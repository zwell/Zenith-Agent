### **标题：构建一个多功能 AI Agent 的技术复盘与问题清单**

**摘要:** 本文记录了从零开始构建一个集成了 LLM、搜索引擎、浏览器和代码沙箱的 AI Agent 的过程。重点复盘了在工程化、API 设计、UI 交互以及 Agent 行为优化中遇到的具体问题、错误堆栈和最终的解决方案。

**项目 GitHub:** `[你的项目链接]`

---

#### **1. 初始架构**

项目的起点是一个基于 `langchain-experimental` 的 `PlanAndExecute` Agent。

* **Planner:** `ChatGoogleGenerativeAI` (`gemini-1.5-flash`)
* **Executor:** `ChatTongyi` (`qwen-turbo`)
* **工具集 (Tools):**
  * `PlayWrightBrowserToolkit`: 浏览器自动化
  * `TavilySearch`: 搜索引擎
  * `E2B Sandbox`: 安全代码执行与文件系统

最初在本地命令行中运行，能够完成一些基本任务，但很快暴露出一系列工程化问题。

---

#### **2. 工程化与 API 设计中遇到的问题与解决方案**

##### **2.1. Python 模块导入错误: `ModuleNotFoundError`**

* **问题:** 将单脚本重构为多目录结构 (如 `src/`, `config/`) 后，执行 `python src/main.py` 导致 `ModuleNotFoundError: No module named 'config'`。
* **原因:** Python 解释器的工作目录与模块的相对路径不匹配。
* **解决方案:** 采用模块化运行。在项目根目录执行 `python -m src.main`，`-m` 参数会将当前目录加入 `sys.path`，解决了模块查找问题。

##### **2.2. Windows 平台下的异步 I/O 问题**

* **问题 1 (`asyncio` 与 `playwright`):** 在 FastAPI 的后台任务中启动 Playwright 时，出现 `NotImplementedError`。
  
  * **堆栈追踪:** `... -> asyncio.base_events.py -> _make_subprocess_transport -> raise NotImplementedError`
  * **原因:** Windows 默认的 `ProactorEventLoop` 不支持 `subprocess_exec`，而 Playwright 需要创建子进程。
  * **解决方案:** 在 FastAPI 应用启动的最开始，强制设置事件循环策略：`if sys.platform == "win32": asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())`。

* **问题 2 (`open()` 编码错误):** 读取 YAML 配置文件时，出现 `UnicodeDecodeError: 'gbk' codec can't decode byte...`。
  
  * **原因:** Windows 默认使用 `GBK` 编码读取文件，而我的配置文件是 `UTF-8` 编码。
  * **解决方案:** 在所有 `open()` 调用中，明确指定编码：`open('...', 'r', encoding='utf-8')`。

##### **2.3. 异步编程中的常见错误**

* **问题 1:** `TypeError: 'coroutine' object does not support the asynchronous context manager protocol`
  
  * **代码:** `async with AsyncSandbox.create(...)`
  * **原因:** `AsyncSandbox.create` 是一个协程函数，返回的是一个协程对象，而不是上下文管理器。忘记了 `await`。
  * **解决方案:** `async with await AsyncSandbox.create(...)`。

* **问题 2:** `TypeError: object async_generator can't be used in 'await' expression`
  
  * **场景:** 在流式 API 中，将一个包含 `yield` 的异步生成器函数作为回调传递，并在下游 `await` 它。
  * **原因:** 异步生成器不能被 `await`，只能被 `async for` 迭代。
  * **解决方案:** 重构流式处理逻辑。采用**生产者-消费者模式**，引入 `asyncio.Queue` 作为中间桥梁。回调函数（生产者）只负责 `await queue.put()`，而主循环（消费者）则 `await queue.get()`，彻底解耦了事件的产生和发送。

##### **2.4. `Ctrl+C` 无法正常退出 `uvicorn`**

* **问题:** 启动一个耗时的 Agent 任务后，`Ctrl+C` 无法终止 `uvicorn` 进程。
* **原因:** `playwright` 或 `e2b` 的子进程没有正确处理或传递 `SIGINT` 信号，导致主事件循环被阻塞。
* **解决方案:** 引入 `asyncio.Event` 作为全局关机信号。通过 `signal.signal()` 捕获 `SIGINT`，然后设置该事件。在长时间运行的任务 (`run_agent_task`) 中，使用 `asyncio.wait` 同时监听 Agent 任务和关机事件，一旦关机事件被触发，就取消 Agent 任务并进行清理。

---

#### **3. Agent 行为优化与 Prompt 工程**

##### **3.1. 问题：LLM 对 API 请求的静默失败 (`ainvoke` 返回 `None`)**

* **现象:** `router_chain.ainvoke(...)` 在某些输入下返回 `None`，且不抛出任何异常，导致下游出现 `AttributeError: 'NoneType' object has no attribute 'route'`。
* **诊断:**
  1. 通过 `langchain.globals.set_debug(True)` 打开详细日志。
  2. 分析日志发现，LLM（`qwen-turbo`）返回了**自然语言回答**，而非期望的 JSON 或分类标签。
  3. `with_structured_output` 或自定义的 JSON 解析器在解析这段自然语言时失败，但 LangChain 的某个封装层“吞掉”了 `JSONDecodeError`，最终返回 `None`。
* **解决方案:**
  1. **强化 Prompt:** 对 Router 的系统提示进行了大幅修改，增加了强硬指令（“你的唯一工作是...只输出XX或XX”）、明确的规则和 few-shot 示例，极大地提高了 LLM 遵循指令的概率。
  2. **简化输出格式:** 最终放弃了要求 LLM 输出 JSON 的方案，改为直接输出预定义的分类标签字符串（`'direct_answer'` 或 `'plan_and_execute'`）。这被证明是更快速、更可靠的方法。
  3. **增加健壮性代码:** 在调用链后，增加了对返回结果的检查和安全回退逻辑，即使路由失败，也会默认进入 `plan_and_execute` 路径，而不是使整个应用崩溃。

##### **3.2. 问题：Planner 面对需要工具的任务时选择“放弃”**

* **现象:** 提问 `“特斯拉最新的股价是多少？”`，Planner 生成的计划是告知用户“我无法提供实时信息”，而不是使用搜索工具。
* **原因:** Planner 在规划时，其“世界观”有限，没有充分意识到 Executor 手中工具的存在和能力。模型的内置安全护栏（不提供金融建议）的优先级高于解决问题的意图。
* **解决方案:** **将工具信息注入 Planner 的提示中**。
  1. 创建了一个 `format_tools_for_prompt` 函数，将工具列表（名称和描述）转换成一段文本。
  2. 在 `PLANNER_PROMPT` 中使用 `{tools}` 占位符。
  3. 在运行时，动态地将格式化后的工具描述填入提示，并明确指示 Planner：“你拥有这些工具，遇到未知信息时必须使用它们”。这从根本上改变了 Planner 的行为模式。

---

#### **4. 前端交互与回调系统**

##### **4.1. 问题：在回调中无法区分 Planner 和 Executor**

* **现象:** `on_chain_start` 被多次触发，无法确定哪一次是 Planner 启动，哪一次是 Executor 启动。
* **原因:** Planner 和 Executor 都是 `PlanAndExecute` Agent 的子链。简单的 `parent_run_id is not None` 逻辑无法区分它们。同时发现，`on_planner_start/end` 这类实验性回调在当前 LangChain 版本中已不存在。
* **解决方案:** **构建一个有状态的回调处理器 `StreamingCallbackHandler`**。
  1. 增加 `self.planner_identified` 和 `self.is_planner_finished` 等状态变量。
  2. 在 `on_chain_start` 中，利用执行顺序的确定性（Planner 总是第一个子链），在第一次遇到子链时就将其标记为 Planner (`self.planner_identified = True`)。
  3. 后续的子链启动事件因为该标志位而不会被误判。
  4. 在 `on_chain_end` 中，通过匹配之前保存的 `run_id` 来精确捕获 Planner 的结束事件，并发送计划。

##### **4.2. Streamlit UI 的流式更新问题**

* **现象:** 日志和计划在 UI 上显示不符合预期，例如内容被覆盖、任务结束后消失。
* **原因:** 对 Streamlit 的“脚本重运行 (rerun)”渲染模型理解不清。局部变量在 rerun 后会丢失，而对 `st.empty()` 的反复调用是替换而非追加。
* **最终方案（讨论中）:** 采用 Streamlit 的标准状态管理模式。
  1. **使用 `st.session_state`** 作为唯一可信的数据源，持久化所有需要跨 rerun 显示的内容（计划、日志列表、结果）。
  2. **分离渲染与逻辑:** UI 渲染部分只负责读取 `session_state` 并显示；事件处理逻辑只负责更新 `session_state`。
  3. 在数据更新后，调用 `st.rerun()` 来触发 UI 的刷新，以显示最新的状态。

---

#### **下一步**

当前的重点是解决浏览器自动化中遇到的挑战，特别是如何让 Agent 能够稳定、准确地定位和操作网页元素。这可能需要探索多模态模型、Accessibility Tree 分析等更前沿的技术。
